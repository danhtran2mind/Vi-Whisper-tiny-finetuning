# Vietnamese Whisper tiny finetuning

## Introduction
Fine-tuned Whisper Tiny model for accurate Vietnamese ASR, with real-time transcription via Gradio or Python API. üéôÔ∏è

## Key Features
- üé§ Fine-tuned Whisper Tiny for Vietnamese ASR
- üåê Real-time transcription with Gradio interface
- üêç Programmatic access via Python API
- ‚ö° Lightweight and efficient for local deployment

## Base Model
This project is built on the following base model: [![HuggingFace Model](https://img.shields.io/badge/HuggingFace-openai%2Fwhisper--tiny-yellow?style=flat&logo=huggingface)](https://huggingface.co/openai/whisper-tiny)

## Demonstration
Experience Vietnamese Whisper Tiny finetuning for ASR:  
- **HuggingFace Space**: [![HuggingFace Space Demo](https://img.shields.io/badge/HuggingFace-danhtran2mind%2FVi--Whisper--tiny--finetuning-yellow?style=flat&logo=huggingface)](https://huggingface.co/spaces/danhtran2mind/Vi-Whisper-tiny-finetuning)  

- **Demo GUI**:  
  <img src="./assets/gradio_app_demo.jpg" alt="Gradio Demo" height="600">

To run the Gradio app locally (`localhost:7860`):  
```bash
python app.py
```

## Installation

### Step 1: Clone the Repository
Clone the project repository and navigate to the project directory:  
```bash
git clone https://github.com/danhtran2mind/Vi-Whisper-tiny-finetuning.git
cd Vi-Whisper-tiny-finetuning
```

### Step 2: Install Dependencies
Install the required Python packages:  
```bash
pip install -r requirements.txt
```

## Usage

### Run Gradio App Locally
Launch the Gradio app for interactive TTS generation:  
```bash
python app.py
```

### Using Python API
Generate ASR Text output programmatically:  
```python
# Load audio file (replace 'audio.wav' with your audio file path)
audio_path = "tests/test_data/example.mp3"
audio, sr = librosa.load(audio_path, sr=16000)

# Preprocess audio
inputs = processor(audio, sampling_rate=16000, return_tensors="pt").to(device)

# Perform inference with max_length and language
with torch.no_grad():
    generated_ids = model.generate(
        inputs["input_features"],
        max_length=448,
    )

# Decode the output
transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

# Print the transcription
print(transcription)

# √îng Th·ªè cho bi·∫øt, l√≤ng l√†m t·ª´ √¥ng r·∫•t ngon, ngon h∆°n nhi·ªÅu so v·ªõi l√≤ng, l·∫°i r·∫•t hi·∫øm. V√¨ v·∫≠y, 
# bu·ªïi khi c√≥ ngu·ªìn cung, √¥ng th∆∞·ªùng t·∫∑ng cho ng∆∞·ªùi th√¢n, b·∫°n b√® th∆∞·ªùng th·ª©c. Nhi·ªÅu ng∆∞·ªùi s√†nh ƒÉn 
# th∆∞·ªùng ƒë·∫°t.
```


## Inference Examples

- Input Audio:

- Output Transcript:
  √îng Th·ªè cho bi·∫øt, l√≤ng l√†m t·ª´ √¥ng r·∫•t ngon, ngon h∆°n nhi·ªÅu so v·ªõi l√≤ng, l·∫°i r·∫•t hi·∫øm. V√¨ v·∫≠y, 
  bu·ªïi khi c√≥ ngu·ªìn cung, √¥ng th∆∞·ªùng t·∫∑ng cho ng∆∞·ªùi th√¢n, b·∫°n b√® th∆∞·ªùng th·ª©c. Nhi·ªÅu ng∆∞·ªùi s√†nh ƒÉn 
  th∆∞·ªùng ƒë·∫°t.

  ## Environment
- **Python**: 3.8 or higher
- **Key Libraries**: See [requirements.txt](requirements.txt) for compatible versions

## Contact
For questions or issues, please use the [GitHub Issues tab](https://github.com/danhtran2mind/Vi-Whisper-tiny-finetuning/issues) or the [Hugging Face Community tab](https://huggingface.co/spaces/danhtran2mind/Vi-Whisper-tiny-finetuning/discussions). üì¨

